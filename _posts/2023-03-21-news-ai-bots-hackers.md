---
layout: post
title:  "AI Bots: The New Hackers' Sidekick?"
author: andre
categories: [News]
image: assets/images/ai-news-bots-hackers.svg
description: Discover how ChatGPT, an AI bot from OpenAI, could potentially help hackers create more convincing phishing emails and whether it's a real threat yet in this conversational, easy-to-read article.
---

Hey there! Did you hear about this ChatGPT AI bot from OpenAI? People are starting to worry that hackers might use it to attack faster and more effectively. But the real crazy stuff has only happened in labs so far, so no need to panic yet.

This ChatGPT thing is an AI created by [OpenAI](https://openai.com/), a company with a ton of money from Microsoft. What it does is read and generate text, which means it could help hackers write phishing emails that look more legit. Like, if a hacker's English isn't great, this AI could make their fake emails way more convincing.

Now, don't freak out just yet. Dustin Childs, the big cheese of threat awareness at Trend Micro's Zero Day Initiative, says ChatGPT is too unpredictable and error-prone to be a reliable weapon right now. He thinks we're years away from [AI](https://techwizco.com/ethics-of-artificial-intelligence/) finding vulnerabilities and exploiting them all on its own. But that won't always be the case, so we should keep an eye on it.

Two security researchers from Claroty, a cybersecurity company, said ChatGPT actually helped them win the Zero Day Initiative's hack-a-thon in Miami last month. Noam Moshe, one of the researchers, said this shows how a hacker could use an AI bot like ChatGPT. Generative AI, which makes realistic text or images based on the data they've consumed, can help hackers up their game.

At the hack-a-thon called Pwn2Own, the goal was to mess with, break into, and take over the Internet of Things and industrial systems. Participants had to choose targets from a list and prepare tactics beforehand. Moshe and his partner found a few weak spots in the systems they picked, and they used ChatGPT to help write code to link the bugs together, which saved them a ton of time. One bug wouldn't have done much, but a chain of them could do some damage. They nailed it 10 out of 10 times and won $123,000!

Moshe said, “A vulnerability on its own isn't interesting, but when we look at the bigger picture and collect vulnerabilities, we can rebuild the chain to take over the system.”

OpenAI and other companies with AI bots like ChatGPT are working on adding controls and filters to prevent abuse, like stopping racist or sexist outputs. But some hackers might still try to get around any security measures the AI bots are taught, said Christopher Whyte, an assistant professor of cybersecurity and homeland security at Virginia Commonwealth University.

Hackers could try to trick the AI bot into writing harmful code by asking it in a sneaky way, without using obvious triggers. Whyte said it's like when a scammer tricks an office worker into giving away their login info or sending money to fake accounts. “You steer the conversation to get the target to bypass controls,” he explained.

So, what do you think? Are AI bots like ChatGPT gonna be the new sidekick for hackers, or are we safe for now? It's definitely a conversation worth having, and we should all be aware of what's happening in the world of AI and cybersecurity. Stay informed, and stay safe out there!
